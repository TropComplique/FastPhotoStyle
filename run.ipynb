{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from cv2.ximgproc import guidedFilter\n",
    "\n",
    "from photorealistic_smoothing import photorealistic_smoothing\n",
    "from secondary_smoothing import secondary_smoothing\n",
    "from networks import VGGEncoder, VGGDecoder\n",
    "from wct import wct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = Image.open('images/Tuebingen_Neckarfront.jpg')\n",
    "w, h = content.size\n",
    "content = content.resize(((w // 8) * 8, (h // 8) * 8), Image.LANCZOS)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = Image.open('styles/andre derain the dance.jpg')\n",
    "style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhotoWCT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PhotoWCT, self).__init__()\n",
    "        self.encoder = VGGEncoder()\n",
    "        self.decoders = nn.ModuleDict({f'{i}': VGGDecoder(i) for i in [1, 2, 3, 4]})\n",
    "\n",
    "    def forward(self, content, style):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            content: a float tensor.\n",
    "            style: a float tensor.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "\n",
    "            style_features, _ = self.encoder(style)\n",
    "            x = content\n",
    "\n",
    "            for i in [1, 2, 3, 4]:\n",
    "                features, pooling_indices = self.encoder(x, level=i)\n",
    "                f = wct(features[i], style_features[i])\n",
    "                x = self.decoders[f'{i}'](f, pooling_indices)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "def to_tensor(x):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        x: an instance of PIL image.\n",
    "    Returns:\n",
    "        a float tensor with shape [1, 3, h, w],\n",
    "        it represents a RGB image with\n",
    "        pixel values in [0, 1] range.\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    x = torch.FloatTensor(x)\n",
    "    return x.permute(2, 0, 1).unsqueeze(0).div(255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = PhotoWCT().cuda()\n",
    "\n",
    "transform.encoder.load_state_dict(torch.load('models/encoder.pth'))\n",
    "for i, m in transform.decoders.items():\n",
    "    m.load_state_dict(torch.load(f'models/decoder{i}.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do whitening and coloring transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_tensor = to_tensor(content).cuda()\n",
    "style_tensor = to_tensor(style).cuda()\n",
    "\n",
    "output_tensor = transform(content_tensor, style_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array = output_tensor.cpu().clamp(0.0, 1.0)[0].permute(1, 2, 0).numpy()\n",
    "output_array = (255 * output_array).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray(output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do first smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "content_array = np.array(content)\n",
    "r1 = photorealistic_smoothing(content_array, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_another = guidedFilter(guide=content_array, src=output_array, radius=35, eps=1e-3)\n",
    "Image.fromarray(r1_another)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do second smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2 = secondary_smoothing(r1, content_array)\n",
    "Image.fromarray(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_another = secondary_smoothing(r1_another, content_array)\n",
    "Image.fromarray(r2_another)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
